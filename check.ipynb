{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd467889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Mean Squared Error: 0.00019527932508369862\n",
      "Random Forest - R-squared: 0.8734532045475106\n",
      "Random Forest - Mean Absolute Error: 0.010425152065249507\n",
      "Random Forest - Mean Squared Log Error: 0.00018439418564478226\n",
      "Random Forest - Explained Variance Score: 0.8943018422104942\n",
      "Gradient Boosting - Mean Squared Error: 0.00045267473754765286\n",
      "Gradient Boosting - R-squared: 0.7066533418507084\n",
      "Gradient Boosting - Mean Absolute Error: 0.01916859532145843\n",
      "Gradient Boosting - Mean Squared Log Error: 0.00041286326376940787\n",
      "Gradient Boosting - Explained Variance Score: 0.7414671831902291\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, explained_variance_score, r2_score\n",
    "\n",
    "# Carica il dataset\n",
    "df = pd.read_csv(\"C:/Users/Utente/Desktop/cakio/dcereijo-player-scores/data/transfers9.csv\")\n",
    "\n",
    "# Rimuovi eventuali righe con valori mancanti\n",
    "df = df.dropna()\n",
    "\n",
    "# Seleziona le colonne che verranno utilizzate come features (variabili indipendenti)\n",
    "features = df[['Overall_club_name', 'Overall_club_involved', 'league_destination', 'age', 'club_name', 'player_name', 'position', 'club_involved_name', 'transfer_period', 'league_name', 'season', 'OverallSeasonClub', 'OverallSeasonClub2']]\n",
    "\n",
    "# Codifica le variabili categoriche\n",
    "features_encoded = pd.get_dummies(features)\n",
    "\n",
    "# Seleziona la variabile target (variabile dipendente)\n",
    "target = df['fee_cleaned']\n",
    "\n",
    "# Suddividi il dataset in set di addestramento e di test\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_encoded, target, test_size=0.002, random_state=42)\n",
    "\n",
    "# Crea il modello di Random Forest\n",
    "rf_model = RandomForestRegressor()\n",
    "\n",
    "# Addestra il modello di Random Forest\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Effettua le previsioni con il modello di Random Forest\n",
    "rf_y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Valuta le prestazioni del modello di Random Forest\n",
    "rf_mse = mean_squared_error(y_test, rf_y_pred)\n",
    "rf_r2 = r2_score(y_test, rf_y_pred)\n",
    "rf_mae = mean_absolute_error(y_test, rf_y_pred)\n",
    "rf_msle = mean_squared_log_error(y_test, rf_y_pred)\n",
    "rf_ev = explained_variance_score(y_test, rf_y_pred)\n",
    "\n",
    "print(\"Random Forest - Mean Squared Error:\", rf_mse)\n",
    "print(\"Random Forest - R-squared:\", rf_r2)\n",
    "print(\"Random Forest - Mean Absolute Error:\", rf_mae)\n",
    "print(\"Random Forest - Mean Squared Log Error:\", rf_msle)\n",
    "print(\"Random Forest - Explained Variance Score:\", rf_ev)\n",
    "\n",
    "# Crea il modello di Gradient Boosting\n",
    "gb_model = GradientBoostingRegressor()\n",
    "\n",
    "# Addestra il modello di Gradient Boosting\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Effettua le previsioni con il modello di Gradient Boosting\n",
    "gb_y_pred = gb_model.predict(X_test)\n",
    "\n",
    "# Valuta le prestazioni del modello di Gradient Boosting\n",
    "gb_mse = mean_squared_error(y_test, gb_y_pred)\n",
    "gb_r2 = r2_score(y_test, gb_y_pred)\n",
    "gb_mae = mean_absolute_error(y_test, gb_y_pred)\n",
    "gb_msle = mean_squared_log_error(y_test, gb_y_pred)\n",
    "gb_ev = explained_variance_score(y_test, gb_y_pred)\n",
    "\n",
    "print(\"Gradient Boosting - Mean Squared Error:\", gb_mse)\n",
    "print(\"Gradient Boosting - R-squared:\", gb_r2)\n",
    "print(\"Gradient Boosting - Mean Absolute Error:\", gb_mae)\n",
    "print(\"Gradient Boosting - Mean Squared Log Error:\", gb_msle)\n",
    "print(\"Gradient Boosting - Explained Variance Score:\", gb_ev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d1cb211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Mean Squared Error: 0.001533070929594319\n",
      "Random Forest - R-squared: 0.443529079596086\n",
      "Random Forest - Mean Absolute Error: 0.024894016039111302\n",
      "Random Forest - Mean Squared Log Error: 0.001301786499214836\n",
      "Random Forest - Explained Variance Score: 0.5654403855233792\n",
      "Gradient Boosting - Mean Squared Error: 0.0005745237633552419\n",
      "Gradient Boosting - R-squared: 0.7914605507047137\n",
      "Gradient Boosting - Mean Absolute Error: 0.020974512001257967\n",
      "Gradient Boosting - Mean Squared Log Error: 0.0005007819638799656\n",
      "Gradient Boosting - Explained Variance Score: 0.8130392683996304\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, explained_variance_score, r2_score\n",
    "\n",
    "# Carica il dataset\n",
    "df = pd.read_csv(\"C:/Users/Utente/Desktop/cakio/dcereijo-player-scores/data/transfers9.csv\")\n",
    "\n",
    "# Rimuovi eventuali righe con valori mancanti\n",
    "df = df.dropna()\n",
    "\n",
    "# Seleziona le colonne che verranno utilizzate come features (variabili indipendenti)\n",
    "features = df[['Overall_club_name', 'Overall_club_involved', 'league_destination', 'age', 'club_name', 'player_name', 'position', 'club_involved_name', 'transfer_period', 'league_name', 'season', 'OverallSeasonClub', 'OverallSeasonClub2']]\n",
    "\n",
    "# Codifica le variabili categoriche\n",
    "features_encoded = pd.get_dummies(features)\n",
    "\n",
    "# Seleziona la variabile target (variabile dipendente)\n",
    "target = df['fee_cleaned']\n",
    "\n",
    "# Suddividi il dataset in set di addestramento e di test\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_encoded, target, test_size=0.002, random_state=15)\n",
    "\n",
    "# Crea il modello di Random Forest\n",
    "rf_model = RandomForestRegressor()\n",
    "\n",
    "# Addestra il modello di Random Forest\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Effettua le previsioni con il modello di Random Forest\n",
    "rf_y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Valuta le prestazioni del modello di Random Forest\n",
    "rf_mse = mean_squared_error(y_test, rf_y_pred)\n",
    "rf_r2 = r2_score(y_test, rf_y_pred)\n",
    "rf_mae = mean_absolute_error(y_test, rf_y_pred)\n",
    "rf_msle = mean_squared_log_error(y_test, rf_y_pred)\n",
    "rf_ev = explained_variance_score(y_test, rf_y_pred)\n",
    "\n",
    "print(\"Random Forest - Mean Squared Error:\", rf_mse)\n",
    "print(\"Random Forest - R-squared:\", rf_r2)\n",
    "print(\"Random Forest - Mean Absolute Error:\", rf_mae)\n",
    "print(\"Random Forest - Mean Squared Log Error:\", rf_msle)\n",
    "print(\"Random Forest - Explained Variance Score:\", rf_ev)\n",
    "\n",
    "# Crea il modello di Gradient Boosting\n",
    "gb_model = GradientBoostingRegressor()\n",
    "\n",
    "# Addestra il modello di Gradient Boosting\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Effettua le previsioni con il modello di Gradient Boosting\n",
    "gb_y_pred = gb_model.predict(X_test)\n",
    "\n",
    "# Valuta le prestazioni del modello di Gradient Boosting\n",
    "gb_mse = mean_squared_error(y_test, gb_y_pred)\n",
    "gb_r2 = r2_score(y_test, gb_y_pred)\n",
    "gb_mae = mean_absolute_error(y_test, gb_y_pred)\n",
    "gb_msle = mean_squared_log_error(y_test, gb_y_pred)\n",
    "gb_ev = explained_variance_score(y_test, gb_y_pred)\n",
    "\n",
    "print(\"Gradient Boosting - Mean Squared Error:\", gb_mse)\n",
    "print(\"Gradient Boosting - R-squared:\", gb_r2)\n",
    "print(\"Gradient Boosting - Mean Absolute Error:\", gb_mae)\n",
    "print(\"Gradient Boosting - Mean Squared Log Error:\", gb_msle)\n",
    "print(\"Gradient Boosting - Explained Variance Score:\", gb_ev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdbdf75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Mean Squared Error: 0.0009416979409956052\n",
      "Random Forest - R-squared: 0.6699008358637042\n",
      "Random Forest - Mean Absolute Error: 0.02156992448914934\n",
      "Random Forest - Mean Squared Log Error: 0.0007322766897392517\n",
      "Random Forest - Explained Variance Score: 0.7453998654875689\n",
      "Gradient Boosting - Mean Squared Error: 0.0015172961272517146\n",
      "Gradient Boosting - R-squared: 0.4681328677181773\n",
      "Gradient Boosting - Mean Absolute Error: 0.02752711033936611\n",
      "Gradient Boosting - Mean Squared Log Error: 0.0011599107955615397\n",
      "Gradient Boosting - Explained Variance Score: 0.7337487569775338\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, explained_variance_score, r2_score\n",
    "\n",
    "# Carica il dataset\n",
    "df = pd.read_csv(\"C:/Users/Utente/Desktop/cakio/dcereijo-player-scores/data/transfers9.csv\")\n",
    "\n",
    "# Rimuovi eventuali righe con valori mancanti\n",
    "df = df.dropna()\n",
    "\n",
    "# Seleziona le colonne che verranno utilizzate come features (variabili indipendenti)\n",
    "features = df[['Overall_club_name', 'Overall_club_involved', 'league_destination', 'age', 'club_name', 'player_name', 'position', 'club_involved_name', 'transfer_period', 'league_name', 'season', 'OverallSeasonClub', 'OverallSeasonClub2']]\n",
    "\n",
    "# Codifica le variabili categoriche\n",
    "features_encoded = pd.get_dummies(features)\n",
    "\n",
    "# Seleziona la variabile target (variabile dipendente)\n",
    "target = df['fee_cleaned']\n",
    "\n",
    "# Suddividi il dataset in set di addestramento e di test\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_encoded, target, test_size=0.002, random_state=1)\n",
    "\n",
    "# Crea il modello di Random Forest\n",
    "rf_model = RandomForestRegressor()\n",
    "\n",
    "# Addestra il modello di Random Forest\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Effettua le previsioni con il modello di Random Forest\n",
    "rf_y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Valuta le prestazioni del modello di Random Forest\n",
    "rf_mse = mean_squared_error(y_test, rf_y_pred)\n",
    "rf_r2 = r2_score(y_test, rf_y_pred)\n",
    "rf_mae = mean_absolute_error(y_test, rf_y_pred)\n",
    "rf_msle = mean_squared_log_error(y_test, rf_y_pred)\n",
    "rf_ev = explained_variance_score(y_test, rf_y_pred)\n",
    "\n",
    "print(\"Random Forest - Mean Squared Error:\", rf_mse)\n",
    "print(\"Random Forest - R-squared:\", rf_r2)\n",
    "print(\"Random Forest - Mean Absolute Error:\", rf_mae)\n",
    "print(\"Random Forest - Mean Squared Log Error:\", rf_msle)\n",
    "print(\"Random Forest - Explained Variance Score:\", rf_ev)\n",
    "\n",
    "# Crea il modello di Gradient Boosting\n",
    "gb_model = GradientBoostingRegressor()\n",
    "\n",
    "# Addestra il modello di Gradient Boosting\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Effettua le previsioni con il modello di Gradient Boosting\n",
    "gb_y_pred = gb_model.predict(X_test)\n",
    "\n",
    "# Valuta le prestazioni del modello di Gradient Boosting\n",
    "gb_mse = mean_squared_error(y_test, gb_y_pred)\n",
    "gb_r2 = r2_score(y_test, gb_y_pred)\n",
    "gb_mae = mean_absolute_error(y_test, gb_y_pred)\n",
    "gb_msle = mean_squared_log_error(y_test, gb_y_pred)\n",
    "gb_ev = explained_variance_score(y_test, gb_y_pred)\n",
    "\n",
    "print(\"Gradient Boosting - Mean Squared Error:\", gb_mse)\n",
    "print(\"Gradient Boosting - R-squared:\", gb_r2)\n",
    "print(\"Gradient Boosting - Mean Absolute Error:\", gb_mae)\n",
    "print(\"Gradient Boosting - Mean Squared Log Error:\", gb_msle)\n",
    "print(\"Gradient Boosting - Explained Variance Score:\", gb_ev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a45d082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Mean Squared Error: 0.0006474000710240136\n",
      "Random Forest - R-squared: 0.5742769732057016\n",
      "Random Forest - Mean Absolute Error: 0.016660968442800798\n",
      "Random Forest - Mean Squared Log Error: 0.0005739728894663484\n",
      "Random Forest - Explained Variance Score: 0.6098040751636389\n",
      "Gradient Boosting - Mean Squared Error: 0.000804229686004985\n",
      "Gradient Boosting - R-squared: 0.47114757707344956\n",
      "Gradient Boosting - Mean Absolute Error: 0.019594908374901243\n",
      "Gradient Boosting - Mean Squared Log Error: 0.0007144845710585243\n",
      "Gradient Boosting - Explained Variance Score: 0.4806565120630606\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, explained_variance_score, r2_score\n",
    "\n",
    "# Carica il dataset\n",
    "df = pd.read_csv(\"C:/Users/Utente/Desktop/cakio/dcereijo-player-scores/data/transfers9.csv\")\n",
    "\n",
    "# Rimuovi eventuali righe con valori mancanti\n",
    "df = df.dropna()\n",
    "\n",
    "# Seleziona le colonne che verranno utilizzate come features (variabili indipendenti)\n",
    "features = df[['Overall_club_name', 'Overall_club_involved', 'league_destination', 'age', 'club_name', 'player_name', 'position', 'club_involved_name', 'transfer_period', 'league_name', 'season', 'OverallSeasonClub', 'OverallSeasonClub2']]\n",
    "\n",
    "# Codifica le variabili categoriche\n",
    "features_encoded = pd.get_dummies(features)\n",
    "\n",
    "# Seleziona la variabile target (variabile dipendente)\n",
    "target = df['fee_cleaned']\n",
    "\n",
    "# Suddividi il dataset in set di addestramento e di test\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_encoded, target, test_size=0.01, random_state=42)\n",
    "\n",
    "# Crea il modello di Random Forest\n",
    "rf_model = RandomForestRegressor()\n",
    "\n",
    "# Addestra il modello di Random Forest\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Effettua le previsioni con il modello di Random Forest\n",
    "rf_y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Valuta le prestazioni del modello di Random Forest\n",
    "rf_mse = mean_squared_error(y_test, rf_y_pred)\n",
    "rf_r2 = r2_score(y_test, rf_y_pred)\n",
    "rf_mae = mean_absolute_error(y_test, rf_y_pred)\n",
    "rf_msle = mean_squared_log_error(y_test, rf_y_pred)\n",
    "rf_ev = explained_variance_score(y_test, rf_y_pred)\n",
    "\n",
    "print(\"Random Forest - Mean Squared Error:\", rf_mse)\n",
    "print(\"Random Forest - R-squared:\", rf_r2)\n",
    "print(\"Random Forest - Mean Absolute Error:\", rf_mae)\n",
    "print(\"Random Forest - Mean Squared Log Error:\", rf_msle)\n",
    "print(\"Random Forest - Explained Variance Score:\", rf_ev)\n",
    "\n",
    "# Crea il modello di Gradient Boosting\n",
    "gb_model = GradientBoostingRegressor()\n",
    "\n",
    "# Addestra il modello di Gradient Boosting\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Effettua le previsioni con il modello di Gradient Boosting\n",
    "gb_y_pred = gb_model.predict(X_test)\n",
    "\n",
    "# Valuta le prestazioni del modello di Gradient Boosting\n",
    "gb_mse = mean_squared_error(y_test, gb_y_pred)\n",
    "gb_r2 = r2_score(y_test, gb_y_pred)\n",
    "gb_mae = mean_absolute_error(y_test, gb_y_pred)\n",
    "gb_msle = mean_squared_log_error(y_test, gb_y_pred)\n",
    "gb_ev = explained_variance_score(y_test, gb_y_pred)\n",
    "\n",
    "print(\"Gradient Boosting - Mean Squared Error:\", gb_mse)\n",
    "print(\"Gradient Boosting - R-squared:\", gb_r2)\n",
    "print(\"Gradient Boosting - Mean Absolute Error:\", gb_mae)\n",
    "print(\"Gradient Boosting - Mean Squared Log Error:\", gb_msle)\n",
    "print(\"Gradient Boosting - Explained Variance Score:\", gb_ev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cc73d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Mean Squared Error: 0.0009073260355550295\n",
      "Random Forest - R-squared: 0.46666188958111143\n",
      "Random Forest - Mean Absolute Error: 0.02024452812850508\n",
      "Random Forest - Mean Squared Log Error: 0.0007120575762034837\n",
      "Random Forest - Explained Variance Score: 0.4903066439584698\n",
      "Gradient Boosting - Mean Squared Error: 0.0008541154681069955\n",
      "Gradient Boosting - R-squared: 0.4979397570564905\n",
      "Gradient Boosting - Mean Absolute Error: 0.021752932322828766\n",
      "Gradient Boosting - Mean Squared Log Error: 0.0007055455193449569\n",
      "Gradient Boosting - Explained Variance Score: 0.5403520990194448\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, explained_variance_score, r2_score\n",
    "\n",
    "# Carica il dataset\n",
    "df = pd.read_csv(\"C:/Users/Utente/Desktop/cakio/dcereijo-player-scores/data/transfers9.csv\")\n",
    "\n",
    "# Rimuovi eventuali righe con valori mancanti\n",
    "df = df.dropna()\n",
    "\n",
    "# Seleziona le colonne che verranno utilizzate come features (variabili indipendenti)\n",
    "features = df[['Overall_club_name', 'Overall_club_involved', 'league_destination', 'age', 'club_name', 'player_name', 'position', 'club_involved_name', 'transfer_period', 'league_name', 'season', 'OverallSeasonClub', 'OverallSeasonClub2']]\n",
    "\n",
    "# Codifica le variabili categoriche\n",
    "features_encoded = pd.get_dummies(features)\n",
    "\n",
    "# Seleziona la variabile target (variabile dipendente)\n",
    "target = df['fee_cleaned']\n",
    "\n",
    "# Suddividi il dataset in set di addestramento e di test\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_encoded, target, test_size=0.008, random_state=1)\n",
    "\n",
    "# Crea il modello di Random Forest\n",
    "rf_model = RandomForestRegressor()\n",
    "\n",
    "# Addestra il modello di Random Forest\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Effettua le previsioni con il modello di Random Forest\n",
    "rf_y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Valuta le prestazioni del modello di Random Forest\n",
    "rf_mse = mean_squared_error(y_test, rf_y_pred)\n",
    "rf_r2 = r2_score(y_test, rf_y_pred)\n",
    "rf_mae = mean_absolute_error(y_test, rf_y_pred)\n",
    "rf_msle = mean_squared_log_error(y_test, rf_y_pred)\n",
    "rf_ev = explained_variance_score(y_test, rf_y_pred)\n",
    "\n",
    "print(\"Random Forest - Mean Squared Error:\", rf_mse)\n",
    "print(\"Random Forest - R-squared:\", rf_r2)\n",
    "print(\"Random Forest - Mean Absolute Error:\", rf_mae)\n",
    "print(\"Random Forest - Mean Squared Log Error:\", rf_msle)\n",
    "print(\"Random Forest - Explained Variance Score:\", rf_ev)\n",
    "\n",
    "# Crea il modello di Gradient Boosting\n",
    "gb_model = GradientBoostingRegressor()\n",
    "\n",
    "# Addestra il modello di Gradient Boosting\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Effettua le previsioni con il modello di Gradient Boosting\n",
    "gb_y_pred = gb_model.predict(X_test)\n",
    "\n",
    "# Valuta le prestazioni del modello di Gradient Boosting\n",
    "gb_mse = mean_squared_error(y_test, gb_y_pred)\n",
    "gb_r2 = r2_score(y_test, gb_y_pred)\n",
    "gb_mae = mean_absolute_error(y_test, gb_y_pred)\n",
    "gb_msle = mean_squared_log_error(y_test, gb_y_pred)\n",
    "gb_ev = explained_variance_score(y_test, gb_y_pred)\n",
    "\n",
    "print(\"Gradient Boosting - Mean Squared Error:\", gb_mse)\n",
    "print(\"Gradient Boosting - R-squared:\", gb_r2)\n",
    "print(\"Gradient Boosting - Mean Absolute Error:\", gb_mae)\n",
    "print(\"Gradient Boosting - Mean Squared Log Error:\", gb_msle)\n",
    "print(\"Gradient Boosting - Explained Variance Score:\", gb_ev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab57d70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
