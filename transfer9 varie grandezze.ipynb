{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8d15e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.0019083681674252617\n",
      "Mean Absolute Error: 0.022689011618173886\n",
      "Mean Squared Log Error: 0.0014063630601509833\n",
      "Explained Variance Score: 0.4480299166479461\n",
      "R-squared: 0.43368965701242024\n",
      "Gradient Boosting - Mean Squared Error: 0.001988491638065319\n",
      "Gradient Boosting - R-squared: 0.4099129293798559\n",
      "Mean Absolute Error: 0.024792771180746066\n",
      "Mean Squared Log Error: 0.001465800850672485\n",
      "Explained Variance Score: 0.4110633936456459\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, explained_variance_score, r2_score\n",
    "###RANDOMFOREST/GRADIENTBOOSTING\n",
    "# Carica il dataset\n",
    "df = pd.read_csv(\"C:/Users/Utente/Desktop/cakio/dcereijo-player-scores/data/transfers9.csv\")\n",
    "\n",
    "# Rimuovi eventuali righe con valori mancanti\n",
    "df = df.dropna()\n",
    "\n",
    "# Seleziona le colonne che verranno utilizzate come features (variabili indipendenti)\n",
    "features = df[[ 'Overall_club_name',  'Overall_club_involved','league_destination','age','club_name', 'player_name', 'position', 'club_involved_name', 'transfer_period', 'league_name', 'season', 'OverallSeasonClub', 'OverallSeasonClub2']]\n",
    "\n",
    "# Codifica le variabili categoriche\n",
    "features_encoded = pd.get_dummies(features)\n",
    "\n",
    "# Seleziona la variabile target (variabile dipendente)\n",
    "target = df['fee_cleaned']\n",
    "\n",
    "# Suddividi il dataset in set di addestramento e di test\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_encoded, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crea il modello di Random Forest\n",
    "rf_model = RandomForestRegressor()\n",
    "\n",
    "# Addestra il modello di Random Forest\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Effettua le previsioni con il modello di Random Forest\n",
    "rf_y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Valuta le prestazioni del modello di Random Forest\n",
    "\n",
    "rf_mse = mean_squared_error(y_test, rf_y_pred)\n",
    "rf_mae = mean_absolute_error(y_test, rf_y_pred)\n",
    "rf_msle = mean_squared_log_error(y_test, rf_y_pred)\n",
    "rf_evs = explained_variance_score(y_test, rf_y_pred)\n",
    "rf_r2 = r2_score(y_test, rf_y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", rf_mse)\n",
    "print(\"Mean Absolute Error:\", rf_mae)\n",
    "print(\"Mean Squared Log Error:\", rf_msle)\n",
    "print(\"Explained Variance Score:\", rf_evs)\n",
    "print(\"R-squared:\", rf_r2)\n",
    "\n",
    "# Crea il modello di Gradient Boosting\n",
    "gb_model = GradientBoostingRegressor()\n",
    "\n",
    "# Addestra il modello di Gradient Boosting\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Effettua le previsioni con il modello di Gradient Boosting\n",
    "gb_y_pred = gb_model.predict(X_test)\n",
    "\n",
    "# Valuta le prestazioni del modello di Gradient Boosting\n",
    "gb_mse = mean_squared_error(y_test, gb_y_pred)\n",
    "gb_r2 = r2_score(y_test, gb_y_pred)\n",
    "gb_mae = mean_absolute_error(y_test, gb_y_pred)\n",
    "gb_msle = mean_squared_log_error(y_test, gb_y_pred)\n",
    "gb_evs = explained_variance_score(y_test, gb_y_pred)\n",
    "print(\"Gradient Boosting - Mean Squared Error:\", gb_mse)\n",
    "print(\"Gradient Boosting - R-squared:\", gb_r2)\n",
    "print(\"Mean Absolute Error:\", gb_mae)\n",
    "print(\"Mean Squared Log Error:\", gb_msle)\n",
    "print(\"Explained Variance Score:\", gb_evs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ea02ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Mean Squared Error: 0.0012342043543834217\n",
      "Random Forest - R-squared: 0.27858367570273745\n",
      "Gradient Boosting - Mean Squared Error: 0.0008693613316906887\n",
      "Gradient Boosting - R-squared: 0.491841481382725\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, explained_variance_score, r2_score\n",
    "###RANDOMFOREST/GRADIENTBOOSTING\n",
    "# Carica il dataset\n",
    "df = pd.read_csv(\"C:/Users/Utente/Desktop/cakio/dcereijo-player-scores/data/transfers9.csv\")\n",
    "\n",
    "# Rimuovi eventuali righe con valori mancanti\n",
    "df = df.dropna()\n",
    "\n",
    "# Seleziona le colonne che verranno utilizzate come features (variabili indipendenti)\n",
    "features = df[[ 'Overall_club_name',  'Overall_club_involved','league_destination','age','club_name', 'player_name', 'position', 'club_involved_name', 'transfer_period', 'league_name', 'season', 'OverallSeasonClub', 'OverallSeasonClub2']]\n",
    "\n",
    "# Codifica le variabili categoriche\n",
    "features_encoded = pd.get_dummies(features)\n",
    "\n",
    "# Seleziona la variabile target (variabile dipendente)\n",
    "target = df['fee_cleaned']\n",
    "\n",
    "# Suddividi il dataset in set di addestramento e di test\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_encoded, target, test_size=0.002, random_state=107)\n",
    "\n",
    "# Crea il modello di Random Forest\n",
    "rf_model = RandomForestRegressor()\n",
    "\n",
    "# Addestra il modello di Random Forest\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Effettua le previsioni con il modello di Random Forest\n",
    "rf_y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Valuta le prestazioni del modello di Random Forest\n",
    "rf_mse = mean_squared_error(y_test, rf_y_pred)\n",
    "rf_r2 = r2_score(y_test, rf_y_pred)\n",
    "\n",
    "print(\"Random Forest - Mean Squared Error:\", rf_mse)\n",
    "print(\"Random Forest - R-squared:\", rf_r2)\n",
    "\n",
    "# Crea il modello di Gradient Boosting\n",
    "gb_model = GradientBoostingRegressor()\n",
    "\n",
    "# Addestra il modello di Gradient Boosting\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Effettua le previsioni con il modello di Gradient Boosting\n",
    "gb_y_pred = gb_model.predict(X_test)\n",
    "\n",
    "# Valuta le prestazioni del modello di Gradient Boosting\n",
    "gb_mse = mean_squared_error(y_test, gb_y_pred)\n",
    "gb_r2 = r2_score(y_test, gb_y_pred)\n",
    "\n",
    "print(\"Gradient Boosting - Mean Squared Error:\", gb_mse)\n",
    "print(\"Gradient Boosting - R-squared:\", gb_r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e40b6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Mean Squared Error: 0.0016555169623466545\n",
      "Random Forest - R-squared: 0.3990838714650242\n",
      "Gradient Boosting - Mean Squared Error: 0.0005745237633552419\n",
      "Gradient Boosting - R-squared: 0.7914605507047137\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, explained_variance_score, r2_score\n",
    "###RANDOMFOREST/GRADIENTBOOSTING\n",
    "# Carica il dataset\n",
    "df = pd.read_csv(\"C:/Users/Utente/Desktop/cakio/dcereijo-player-scores/data/transfers9.csv\")\n",
    "\n",
    "# Rimuovi eventuali righe con valori mancanti\n",
    "df = df.dropna()\n",
    "\n",
    "# Seleziona le colonne che verranno utilizzate come features (variabili indipendenti)\n",
    "features = df[[ 'Overall_club_name',  'Overall_club_involved','league_destination','age','club_name', 'player_name', 'position', 'club_involved_name', 'transfer_period', 'league_name', 'season', 'OverallSeasonClub', 'OverallSeasonClub2']]\n",
    "\n",
    "# Codifica le variabili categoriche\n",
    "features_encoded = pd.get_dummies(features)\n",
    "\n",
    "# Seleziona la variabile target (variabile dipendente)\n",
    "target = df['fee_cleaned']\n",
    "\n",
    "# Suddividi il dataset in set di addestramento e di test\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_encoded, target, test_size=0.002, random_state=15)\n",
    "\n",
    "# Crea il modello di Random Forest\n",
    "rf_model = RandomForestRegressor()\n",
    "\n",
    "# Addestra il modello di Random Forest\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Effettua le previsioni con il modello di Random Forest\n",
    "rf_y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Valuta le prestazioni del modello di Random Forest\n",
    "rf_mse = mean_squared_error(y_test, rf_y_pred)\n",
    "rf_r2 = r2_score(y_test, rf_y_pred)\n",
    "\n",
    "print(\"Random Forest - Mean Squared Error:\", rf_mse)\n",
    "print(\"Random Forest - R-squared:\", rf_r2)\n",
    "\n",
    "# Crea il modello di Gradient Boosting\n",
    "gb_model = GradientBoostingRegressor()\n",
    "\n",
    "# Addestra il modello di Gradient Boosting\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Effettua le previsioni con il modello di Gradient Boosting\n",
    "gb_y_pred = gb_model.predict(X_test)\n",
    "\n",
    "# Valuta le prestazioni del modello di Gradient Boosting\n",
    "gb_mse = mean_squared_error(y_test, gb_y_pred)\n",
    "gb_r2 = r2_score(y_test, gb_y_pred)\n",
    "\n",
    "print(\"Gradient Boosting - Mean Squared Error:\", gb_mse)\n",
    "print(\"Gradient Boosting - R-squared:\", gb_r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "686a48cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Mean Squared Error: 0.0005210329615128077\n",
      "Random Forest - R-squared: 0.6623551849316069\n",
      "Gradient Boosting - Mean Squared Error: 0.00045267473754765264\n",
      "Gradient Boosting - R-squared: 0.7066533418507085\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, explained_variance_score, r2_score\n",
    "###RANDOMFOREST/GRADIENTBOOSTING\n",
    "# Carica il dataset\n",
    "df = pd.read_csv(\"C:/Users/Utente/Desktop/cakio/dcereijo-player-scores/data/transfers9.csv\")\n",
    "\n",
    "# Rimuovi eventuali righe con valori mancanti\n",
    "df = df.dropna()\n",
    "\n",
    "# Seleziona le colonne che verranno utilizzate come features (variabili indipendenti)\n",
    "features = df[[ 'Overall_club_name',  'Overall_club_involved','league_destination','age','club_name', 'player_name', 'position', 'club_involved_name', 'transfer_period', 'league_name', 'season', 'OverallSeasonClub', 'OverallSeasonClub2']]\n",
    "\n",
    "# Codifica le variabili categoriche\n",
    "features_encoded = pd.get_dummies(features)\n",
    "\n",
    "# Seleziona la variabile target (variabile dipendente)\n",
    "target = df['fee_cleaned']\n",
    "\n",
    "# Suddividi il dataset in set di addestramento e di test\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_encoded, target, test_size=0.002, random_state=42)\n",
    "\n",
    "# Crea il modello di Random Forest\n",
    "rf_model = RandomForestRegressor()\n",
    "\n",
    "# Addestra il modello di Random Forest\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Effettua le previsioni con il modello di Random Forest\n",
    "rf_y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Valuta le prestazioni del modello di Random Forest\n",
    "rf_mse = mean_squared_error(y_test, rf_y_pred)\n",
    "rf_r2 = r2_score(y_test, rf_y_pred)\n",
    "\n",
    "print(\"Random Forest - Mean Squared Error:\", rf_mse)\n",
    "print(\"Random Forest - R-squared:\", rf_r2)\n",
    "\n",
    "# Crea il modello di Gradient Boosting\n",
    "gb_model = GradientBoostingRegressor()\n",
    "\n",
    "# Addestra il modello di Gradient Boosting\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Effettua le previsioni con il modello di Gradient Boosting\n",
    "gb_y_pred = gb_model.predict(X_test)\n",
    "\n",
    "# Valuta le prestazioni del modello di Gradient Boosting\n",
    "gb_mse = mean_squared_error(y_test, gb_y_pred)\n",
    "gb_r2 = r2_score(y_test, gb_y_pred)\n",
    "\n",
    "print(\"Gradient Boosting - Mean Squared Error:\", gb_mse)\n",
    "print(\"Gradient Boosting - R-squared:\", gb_r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9aceb847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 136ms/step\n",
      "Mean Squared Error: 0.006753589164139696\n",
      "Mean Absolute Error: 0.0580577520547745\n",
      "Mean Squared Log Error: 0.005496162483806969\n",
      "Explained Variance Score: -0.3798721869286439\n",
      "R-squared: -0.3936374754625016\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, explained_variance_score, r2_score\n",
    "\n",
    "##NEURAL\n",
    "# Carica il dataset\n",
    "df = pd.read_csv(\"C:/Users/Utente/Desktop/cakio/dcereijo-player-scores/data/transfers9.csv\")\n",
    "\n",
    "# Rimuovi eventuali righe con valori mancanti\n",
    "df = df.dropna()\n",
    "\n",
    "# Seleziona le colonne che verranno utilizzate come features (variabili indipendenti)\n",
    "features = df[[ 'Overall_club_name',  'Overall_club_involved','league_destination','age','club_name', 'player_name', 'position', 'club_involved_name', 'transfer_period', 'league_name', 'season', 'OverallSeasonClub', 'OverallSeasonClub2']]\n",
    "\n",
    "# Codifica le variabili categoriche\n",
    "features_encoded = pd.get_dummies(features)\n",
    "\n",
    "# Seleziona la variabile target (variabile dipendente)\n",
    "target = df['fee_cleaned']\n",
    "\n",
    "# Suddividi il dataset in set di addestramento e di test\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_encoded, target, test_size=0.002, random_state=70)\n",
    "\n",
    "# Standardizzazione delle features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Crea il modello di rete neurale\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compila il modello\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "\n",
    "# Addestra il modello\n",
    "model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, verbose=0)\n",
    "\n",
    "# Effettua le previsioni sul set di test\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Valuta le prestazioni del modello\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "msle = mean_squared_log_error(y_test, y_pred)\n",
    "evs = explained_variance_score(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Mean Squared Log Error:\", msle)\n",
    "print(\"Explained Variance Score:\", evs)\n",
    "print(\"R-squared:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ec8a1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.002831015558958415\n",
      "Mean Absolute Error: 0.025042303604091477\n",
      "Mean Squared Log Error: 0.00210975057613476\n",
      "Explained Variance Score: 0.16622132482969254\n",
      "R-squared: 0.15463974268387737\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, explained_variance_score, r2_score\n",
    "##DECISIONTREE\n",
    "# Carica il dataset dal file CSV\n",
    "data = pd.read_csv(\"C:/Users/Utente/Desktop/cakio/dcereijo-player-scores/data/transfers9.csv\")\n",
    "\n",
    "\n",
    "# Seleziona le colonne di input (variabili indipendenti)\n",
    "features = [ 'Overall_club_name',  'Overall_club_involved','league_destination','age','club_name', 'player_name', 'position', 'club_involved_name', 'transfer_period', 'league_name', 'season', 'OverallSeasonClub', 'OverallSeasonClub2']\n",
    "X = data[features]\n",
    "\n",
    "# Seleziona la variabile target (variabile dipendente)\n",
    "y = data['fee_cleaned']\n",
    "\n",
    "# Effettua la codifica delle variabili categoriche\n",
    "X_encoded = pd.get_dummies(X)\n",
    "\n",
    "# Suddividi il dataset in set di addestramento e set di test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crea e addestra il modello dell'albero decisionale\n",
    "model = DecisionTreeRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Effettua le previsioni sul set di test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Valuta le prestazioni del modello\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "msle = mean_squared_log_error(y_test, y_pred)\n",
    "evs = explained_variance_score(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Mean Squared Log Error:\", msle)\n",
    "print(\"Explained Variance Score:\", evs)\n",
    "print(\"R-squared:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ca78551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.0023198256026346824\n",
      "Mean Absolute Error: 0.03168933193392761\n",
      "Mean Squared Log Error: 0.001972067318729377\n",
      "Explained Variance Score: -0.2354131759613709\n",
      "R-squared: -0.24083813654309583\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, explained_variance_score, r2_score\n",
    "##DECISIONTREE\n",
    "# Carica il dataset dal file CSV\n",
    "data = pd.read_csv(\"C:/Users/Utente/Desktop/cakio/dcereijo-player-scores/data/transfers9.csv\")\n",
    "\n",
    "\n",
    "# Seleziona le colonne di input (variabili indipendenti)\n",
    "features = [ 'Overall_club_name',  'Overall_club_involved','league_destination','age','club_name', 'player_name', 'position', 'club_involved_name', 'transfer_period', 'league_name', 'season', 'OverallSeasonClub', 'OverallSeasonClub2']\n",
    "X = data[features]\n",
    "\n",
    "# Seleziona la variabile target (variabile dipendente)\n",
    "y = data['fee_cleaned']\n",
    "\n",
    "# Effettua la codifica delle variabili categoriche\n",
    "X_encoded = pd.get_dummies(X)\n",
    "\n",
    "# Suddividi il dataset in set di addestramento e set di test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.002, random_state=42)\n",
    "\n",
    "# Crea e addestra il modello dell'albero decisionale\n",
    "model = DecisionTreeRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Effettua le previsioni sul set di test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Valuta le prestazioni del modello\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "msle = mean_squared_log_error(y_test, y_pred)\n",
    "evs = explained_variance_score(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Mean Squared Log Error:\", msle)\n",
    "print(\"Explained Variance Score:\", evs)\n",
    "print(\"R-squared:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1e79ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-d5f637e0a9b8>:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[column] = label_encoder.fit_transform(X[column])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.0020790133834012775\n",
      "Mean Absolute Error: 0.02137386252934491\n",
      "Explained Variance Score: 0.36704155919863113\n",
      "R-squared: 0.3666669678716603\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, explained_variance_score, r2_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Carica il dataset dal file CSV\n",
    "data = pd.read_csv(\"C:/Users/Utente/Desktop/cakio/dcereijo-player-scores/data/transfers9.csv\")\n",
    "\n",
    "# Seleziona le colonne che verranno utilizzate come features (variabili indipendenti)\n",
    "features = ['Overall_club_name', 'Overall_club_involved', 'league_destination', 'age', 'club_name', 'player_name', 'position', 'club_involved_name', 'transfer_period', 'league_name', 'season', 'OverallSeasonClub', 'OverallSeasonClub2']\n",
    "\n",
    "X = data[features]\n",
    "\n",
    "# Seleziona la variabile target (variabile dipendente)\n",
    "y = data['fee_cleaned']\n",
    "df.dropna(inplace=True)\n",
    "# Effettua la codifica delle variabili categoriche\n",
    "label_encoder = LabelEncoder()\n",
    "for column in X.select_dtypes(include=['object']):\n",
    "    X[column] = label_encoder.fit_transform(X[column])\n",
    "\n",
    "# Suddividi il dataset in set di addestramento e set di test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Crea e addestra il modello GBM\n",
    "model = GradientBoostingRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Effettua le previsioni sul set di test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Valuta le prestazioni del modello\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "evs = explained_variance_score(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "\n",
    "print(\"Explained Variance Score:\", evs)\n",
    "print(\"R-squared:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb4c322a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-abe607e81721>:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[column] = label_encoder.fit_transform(X[column])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.002491952459286927\n",
      "Mean Absolute Error: 0.02988245463925709\n",
      "Mean Squared Log Error: 0.002102342519772035\n",
      "Explained Variance Score: -0.31190983162762054\n",
      "R-squared: -0.3329060781223343\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, explained_variance_score, r2_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Carica il dataset dal file CSV\n",
    "data = pd.read_csv(\"C:/Users/Utente/Desktop/cakio/dcereijo-player-scores/data/transfers9.csv\")\n",
    "\n",
    "# Seleziona le colonne che verranno utilizzate come features (variabili indipendenti)\n",
    "features = ['Overall_club_name', 'Overall_club_involved', 'league_destination', 'age', 'club_name', 'player_name', 'position', 'club_involved_name', 'transfer_period', 'league_name', 'season', 'OverallSeasonClub', 'OverallSeasonClub2']\n",
    "\n",
    "X = data[features]\n",
    "\n",
    "# Seleziona la variabile target (variabile dipendente)\n",
    "y = data['fee_cleaned']\n",
    "df.dropna(inplace=True)\n",
    "# Effettua la codifica delle variabili categoriche\n",
    "label_encoder = LabelEncoder()\n",
    "for column in X.select_dtypes(include=['object']):\n",
    "    X[column] = label_encoder.fit_transform(X[column])\n",
    "\n",
    "# Suddividi il dataset in set di addestramento e set di test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.002, random_state=42)\n",
    "\n",
    "# Crea e addestra il modello GBM\n",
    "model = GradientBoostingRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Effettua le previsioni sul set di test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "msle = mean_squared_log_error(y_test, y_pred)\n",
    "evs = explained_variance_score(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Mean Squared Log Error:\", msle)\n",
    "print(\"Explained Variance Score:\", evs)\n",
    "print(\"R-squared:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7057729a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utente\\anaconda4\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.0020891940327951823\n",
      "Mean Absolute Error: 0.023932398458282787\n",
      "Mean Squared Log Error: 0.0015576894660506734\n",
      "Explained Variance Score: 0.37867633369254394\n",
      "R-squared: 0.3761526320269206\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, explained_variance_score, r2_score\n",
    "\n",
    "# Carica il dataset dal tuo CSV\n",
    "df = pd.read_csv(\"C:/Users/Utente/Desktop/cakio/dcereijo-player-scores/data/transfers9.csv\")\n",
    "\n",
    "# Seleziona le feature che desideri utilizzare per la regressione\n",
    "features = ['age', 'OverallSeasonClub', 'OverallSeasonClub2', 'Overall_club_name', 'Overall_club_involved']\n",
    "\n",
    "# Seleziona la variabile target\n",
    "target = 'fee_cleaned'\n",
    "\n",
    "# Dividi il dataset in caratteristiche e variabile target\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "df.dropna(inplace=True)\n",
    "# Codifica le caratteristiche categoriche\n",
    "cat_features = ['club_name', 'player_name', 'position', 'club_involved_name', 'transfer_period', 'league_name', 'season','league_destination']\n",
    "encoder = OneHotEncoder(sparse=False, drop='first')\n",
    "X_encoded = pd.DataFrame(encoder.fit_transform(df[cat_features]))\n",
    "X_encoded.columns = encoder.get_feature_names(cat_features)\n",
    "\n",
    "# Concatena le caratteristiche codificate con quelle numeriche\n",
    "X = pd.concat([X, X_encoded], axis=1)\n",
    "\n",
    "# Dividi i dati in set di addestramento e di test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Crea il modello XGBoost con i parametri ottimali precedentemente rilevati\n",
    "xgb_model = xgb.XGBRegressor(learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8,\n",
    "                             colsample_bytree=1.0, reg_alpha=0, reg_lambda=0.1)\n",
    "\n",
    "# Addestra il modello\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Fai le previsioni sul set di test utilizzando il modello addestrato\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Applica una trasformazione logaritmica ai valori target\n",
    "y_test = np.abs(y_test)\n",
    "y_pred = np.abs(y_pred)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "msle = mean_squared_log_error(y_test, y_pred)\n",
    "evs = explained_variance_score(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Mean Squared Log Error:\", msle)\n",
    "print(\"Explained Variance Score:\", evs)\n",
    "print(\"R-squared:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b7cdfdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.0017693421567933584\n",
      "Mean Absolute Error: 0.020859550109365705\n",
      "Explained Variance Score: 0.47465776841627616\n",
      "R-squared: 0.47166255013539904\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, explained_variance_score, r2_score\n",
    "###XGBOOST\n",
    "# Carica il dataset dal tuo CSV\n",
    "df = pd.read_csv(\"C:/Users/Utente/Desktop/cakio/dcereijo-player-scores/data/transfers9.csv\")\n",
    "\n",
    "# Seleziona le feature che desideri utilizzare per la regressione\n",
    "features = ['age', 'OverallSeasonClub', 'OverallSeasonClub2', 'Overall_club_name',  'Overall_club_involved']\n",
    "\n",
    "# Seleziona la variabile target\n",
    "target = 'fee_cleaned'\n",
    "\n",
    "# Dividi il dataset in caratteristiche e variabile target\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Codifica le caratteristiche categoriche\n",
    "cat_features = ['club_name', 'player_name', 'position', 'club_involved_name', 'transfer_period', 'league_name', 'season','league_destination']\n",
    "encoder = OneHotEncoder(sparse=False, drop='first')\n",
    "X_encoded = pd.DataFrame(encoder.fit_transform(df[cat_features]))\n",
    "\n",
    "# Concatena le caratteristiche codificate con quelle numeriche\n",
    "X = pd.concat([X, X_encoded], axis=1)\n",
    "\n",
    "# Dividi i dati in set di addestramento e di test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crea il modello XGBoost\n",
    "xgboost_model = xgb.XGBRegressor()\n",
    "\n",
    "# Adatta il modello ai dati di addestramento\n",
    "xgboost_model.fit(X_train, y_train)\n",
    "\n",
    "# Fai le previsioni sul set di test\n",
    "y_pred = xgboost_model.predict(X_test)\n",
    "\n",
    "# Valuta le prestazioni del modello\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "evs = explained_variance_score(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "\n",
    "print(\"Explained Variance Score:\", evs)\n",
    "print(\"R-squared:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d509c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utente\\anaconda4\\lib\\site-packages\\sklearn\\base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- club_involved_name_Manchester City\n",
      "- player_name_Elia Petrelli\n",
      "- player_name_Manolo Portanova\n",
      "- player_name_Nicolò Rovella\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- club_involved_name_1. FC Köln\n",
      "- club_involved_name_1.FC Heidenheim\n",
      "- club_involved_name_1.FC K'lautern\n",
      "- club_involved_name_1.FC Köln U19\n",
      "- club_involved_name_1.FC Magdeburg\n",
      "- ...\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 32 features, but RandomForestRegressor is expecting 6351 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-a360ba48eeae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;31m# Effettua le previsioni con il modello di Random Forest sui dati di test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[0mrf_y_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_features_encoded\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;31m# Valuta le prestazioni del modello di Random Forest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda4\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    969\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    970\u001b[0m         \u001b[1;31m# Check data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 971\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    972\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    973\u001b[0m         \u001b[1;31m# Assign chunk of trees to jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda4\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    577\u001b[0m         Validate X whenever one tries to predict, apply, predict_proba.\"\"\"\n\u001b[0;32m    578\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    580\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintc\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No support for np.int64 index based sparse matrices\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda4\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ensure_2d\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda4\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    401\u001b[0m                 \u001b[1;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m                 \u001b[1;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: X has 32 features, but RandomForestRegressor is expecting 6351 features as input."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, explained_variance_score, r2_score\n",
    "\n",
    "# Carica i dati di addestramento e test\n",
    "train_data = pd.read_csv(\"C:/Users/Utente/Desktop/cakio/dcereijo-player-scores/data/Rest.csv\")\n",
    "test_data = pd.read_csv(\"C:/Users/Utente/Desktop/cakio/dcereijo-player-scores/data/Juve.csv\")\n",
    "\n",
    "# Seleziona le colonne che verranno utilizzate come features (variabili indipendenti) dai dati di addestramento\n",
    "train_features = train_data[['Overall_club_name', 'Overall_club_involved', 'league_destination', 'age', 'club_name', 'player_name', 'position', 'club_involved_name', 'transfer_period', 'league_name', 'season', 'OverallSeasonClub', 'OverallSeasonClub2']]\n",
    "# Seleziona la variabile target (variabile dipendente) dai dati di addestramento\n",
    "train_target = train_data['fee_cleaned']\n",
    "\n",
    "# Seleziona le colonne che verranno utilizzate come features (variabili indipendenti) dai dati di test\n",
    "test_features = test_data[['Overall_club_name', 'Overall_club_involved', 'league_destination', 'age', 'club_name', 'player_name', 'position', 'club_involved_name', 'transfer_period', 'league_name', 'season', 'OverallSeasonClub', 'OverallSeasonClub2']]\n",
    "# Seleziona la variabile target (variabile dipendente) dai dati di test\n",
    "test_target = test_data['fee_cleaned']\n",
    "\n",
    "# Codifica le variabili categoriche nei dati di addestramento e test\n",
    "train_features_encoded = pd.get_dummies(train_features)\n",
    "test_features_encoded = pd.get_dummies(test_features)\n",
    "\n",
    "# Crea il modello di Random Forest\n",
    "rf_model = RandomForestRegressor()\n",
    "\n",
    "# Addestra il modello di Random Forest\n",
    "rf_model.fit(train_features_encoded, train_target)\n",
    "\n",
    "# Effettua le previsioni con il modello di Random Forest sui dati di test\n",
    "rf_y_pred = rf_model.predict(test_features_encoded)\n",
    "\n",
    "# Valuta le prestazioni del modello di Random Forest\n",
    "rf_mse = mean_squared_error(test_target, rf_y_pred)\n",
    "rf_r2 = r2_score(test_target, rf_y_pred)\n",
    "\n",
    "print(\"Random Forest - Mean Squared Error:\", rf_mse)\n",
    "print(\"Random Forest - R-squared:\", rf_r2)\n",
    "\n",
    "# Crea il modello di Gradient Boosting\n",
    "gb_model = GradientBoostingRegressor()\n",
    "\n",
    "# Addestra il modello di Gradient Boosting\n",
    "gb_model.fit(train_features_encoded, train_target)\n",
    "\n",
    "# Effettua le previsioni con il modello di Gradient Boosting sui dati di test\n",
    "gb_y_pred = gb_model.predict(test_features_encoded)\n",
    "\n",
    "# Valuta le prestazioni del modello di Gradient Boosting\n",
    "gb_mse = mean_squared_error(test_target, gb_y_pred)\n",
    "gb_r2 = r2_score(test_target, gb_y_pred)\n",
    "\n",
    "print(\"Gradient Boosting - Mean Squared Error:\", gb_mse)\n",
    "print(\"Gradient Boosting - R-squared:\", gb_r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ffe985",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
